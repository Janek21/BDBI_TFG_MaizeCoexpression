library(randomcoloR)
library(edgeR)
library(tidyverse)
library(dplyr)
library(grid)
library(gridExtra)
#devtools::install_github("kevinblighe/CorLevelPlot")
library(CorLevelPlot)
library(ggpubr)
library(plotly)
library(factoextra)
library(umap)
library(heatmaply)
library(dbscan)
library(reticulate)
reticulate::use_python("/usr/bin/python3", required=TRUE)
setwd("..") #set path to general annotation_code directory
dataPath<-paste0("../data/wlen/data_wlen.csv")
metadataPath<-paste0("../data/metadata.txt")
moduledata<-"../coexpression_code/geneModule.txt"
dataNL<-read.delim(dataPath, row.names=1, stringsAsFactors=TRUE)
metadata<-read.delim(metadataPath, header=T, row.names=1, stringsAsFactors=TRUE)
genemodule<-read.table(moduledata, stringsAsFactors=TRUE)
colnames(metadata)<-c("specie", "quality", "tissue_abv", "rep", "location")
moduleList<-levels(genemodule$modules)
table(genemodule$modules)
#Data selection
ME<-"violet" #green #lightcyan #turquoise
genemodule$genes<-rownames(genemodule)
MEgeneList<-rownames(genemodule[genemodule$modules==ME,])
dataNL<-dataNL[MEgeneList,]
if ("Length" %in% colnames(dataNL)){
length_vec<-dataNL$Length
}
dim(dataNL)
dim(metadata)
dataMatcher<-function(data, metadata){
options(warn=-1)
cat("Data begins with:" , dim(data))
cat("\nMetadata begins with:", dim(metadata))
#Match data to metadata
data <- data[, order(colnames(data))]
metadata <- metadata[order(rownames(metadata)), ]
cat("\nColumns data = Rows of metatdata?", all(rownames(metadata) == colnames(data)))
#If TRUE, columns of data and rows of metadata are matched
cat("\nRemove the excess from data")
data<-data[,colnames(data) %in% rownames(metadata)] #remove data not present in metadata
cat("\nData end with:" , dim(data))
cat("\nRemove the excess from metadata")
metadata<-metadata[rownames(metadata) %in% colnames(data),] #remove metadata not present in data
cat("\nMetadata end with:" , dim(metadata), "\n")
options(warn=0)
return(list(data, metadata))
}
jointData<-dataMatcher(dataNL, metadata)
dataNL<-jointData[[1]]
metadata<-jointData[[2]]
outDetect<-goodSamplesGenes(t(dataNL))
table(outDetect$goodGenes) #False genes are outliers
table(outDetect$goodSamples) #All samples are True = no outliers
dataNL<-dataNL[outDetect$goodGenes==TRUE,] #remove ouliers
if (exists("length_vec")){ #only if it exists
length_vec<-length_vec[outDetect$goodGenes==TRUE] #if length_vec exists remove outliers from there as well
}
#add the name of the species to the replicate, to be able to differentiate it
#save location
metadata$org_location<-as.factor(metadata$location)
#create specialized location
metadata$location<-paste(metadata$specie, metadata$location, sep="_")
metadata$location<-as.factor(metadata$location)
rsumer<-function(data, metadata, tissue_name){ #calculates the mean of all columns that belong to a location (ex: mean of all COB columns)
loc_mdata<-metadata[metadata$location == tissue_name, ] #filter metadata tissue (get metadata of location only)
data<-data[,colnames(data) %in% rownames(loc_mdata)] #get data of location only, based on metadata
if (1<ncol(data.frame(data))){ #If there's only 1 replicate, don't try to do the mean (it gives error)
data<-rowMeans(data) #calculate mean for each gene out of the locations(replicates)
}
return(as.data.frame(data))
}
tissue_data<-levels(metadata$location) #get list of tissue names
d_joint<-sapply(tissue_data, function(tissue_name) rsumer(dataNL, metadata, tissue_name)) #returns an array where each entry is a column with the mean data of the replicates (rows are genes)
repl_data<-as.data.frame(d_joint) #data joint by replicate
colnames(repl_data) = gsub(pattern = "*.data", replacement = "", x = tolower(colnames(repl_data))) #get column names to be only location
rownames(repl_data)<-rownames(dataNL) #rename rows to be genes again
#Create a column for the location+species
repl_meta<-as.data.frame(colnames(repl_data))
colnames(repl_meta)<-c("location")
#Split the created column and add 2 columns to repl_meta, one for the species and one for the tissue
temp_meta<-data.frame(t(data.frame(strsplit(as.character(repl_meta$location), "_"))))
repl_meta<-data.frame(repl_meta$location, temp_meta$X1, temp_meta$X2)
colnames(repl_meta)<-c("location", "species", "org_location")
keep<-colSums(repl_data)!=0
repl_data<-repl_data[,keep]
if (exists("length_vec")){ #if we have lengths
length_vec<-data.frame(Length=length_vec) #convert to dataframe
dge <- DGEList(repl_data, genes=length_vec) #use edgeR for normalization
dge <- calcNormFactors(dge)
Nrepl_data <- rpkm(dge, log=TRUE)
Nrepl_data<-as.data.frame(Nrepl_data)
NormType<-"RPKM"
}
#Filter low expression genes
keep<-apply(Nrepl_data, 1, max)>=0 #keep genes where the counts for at least one replicate are of at least 1 (0 because of log)
Nrepl_data<-Nrepl_data[keep,]
#Nrepl to data frame
Nrepl_data<-as.data.frame(Nrepl_data) #evetually transpose
#More genes kept after normalization and filtering than cpm
set.seed(42)
#Choose which genes to use
geneNumber<-round(nrow(Nrepl_data)/100 *10) #1% of genes
#get random genes
chosenGenes<-sample(rownames(Nrepl_data), geneNumber)
#obtain genes data
dataSection<-Nrepl_data[chosenGenes,]
#Save tissues
tissues<-colnames(dataSection)
#create genes column
dataSection$Gene<-rownames(dataSection)
#reshape data
long_data<-reshape(dataSection, direction="long",
v.names="Expression",
timevar="Tissue",
varying=tissues,
times=names(dataSection)[1:(ncol(dataSection)-1)]) #names(dataSection)[1:(ncol(dataSection)-1)]
ggplot(long_data, aes(x=Tissue, y=Expression, group=Gene)) +
geom_line(size=1, alpha=0.2) +
labs(x="Tissues", y="Expression", title=paste0("Module: ", ME, " at genes: ", geneNumber))+
theme_classic()+
theme(axis.text.x=element_text(angle=45, hjust=1, size=10),
axis.text.y=element_text(size=12),
legend.position="none",
axis.ticks=element_line(colour="black"),
axis.ticks.length=unit(8, "pt"),
panel.grid.major=element_line(color="red",
size=0.5))
ggplot(long_data, aes(x=Tissue, y=Expression, group=Gene)) +
geom_line(size=1, alpha=0.1) +
labs(x="Tissues", y="Expression", title=paste0("Module: ", ME, " at genes: ", geneNumber))+
theme_classic()+
theme(axis.text.x=element_text(angle=45, hjust=1, size=10),
axis.text.y=element_text(size=12),
legend.position="none",
axis.ticks=element_line(colour="black"),
axis.ticks.length=unit(8, "pt"))
Nrepl_dataT<-as.data.frame(t(Nrepl_data))
#correaltion table
geneCor<-cor(Nrepl_dataT, method="pearson")
geneList<-rownames(geneCor)
#Threshold choosing
ths<-seq(0,1, by=0.05)
ths_effect<- data.frame(ths, count=sapply(ths, function(t) sum(abs(geneCor)>t))) #count amount of correlations (all positive, as they all contribute)
ggplot(ths_effect, aes(x=ths, y=count))+
geom_line(color=ME, size=2)+
labs(x="Threshold", y="Correlaton count")+
geom_point(size=4)+
theme_bw()
#A good correlation threshold would be 0.7
#select above the diagonal
cor_vals<-geneCor[upper.tri(geneCor)]
#convert to data frame
cor_df<-data.frame(Correlation=cor_vals)
#PLot distribution
ggplot(cor_df, aes(x=Correlation))+
geom_histogram(binwidth=0.05, fill=ME, color="black")+
labs(title="Distribution of correlation values",
x="Correlation Coefficient",
y="Frequency")+
theme_minimal()
#Tends to appear bimodal
set.seed(42)
#Z-score scaling
sc_data<-scale(Nrepl_data)
#scaled pca
sc_pca<-prcomp(sc_data, scale=TRUE)
#pca plot
ggplot(sc_pca$x, aes(x=PC1, y=PC2))+
geom_point(size=3)+
theme_minimal()
#pca PC effect
pca_sum<-summary(sc_pca)
pca_data<-as.data.frame(t(pca_sum$importance))
c_var<-pca_data$`Cumulative Proportion`
PC_c<-1:length(c_var)
#search cutoff
plot(pca_data$`Cumulative Proportion`, xlab="PC component number", ylab="Cumulative variance", main="Elbow plot for PC component cutoff", lwd=2)
abline(v=PC_c[1], col="red", lwd=2)
abline(h=c_var[length(c_var)], col="red", lwd=2)
#function to calculate distance vector (distance to "triangle" corner)
dVector_calculator<-function(xn, yn, point_x, point_y){
#normalize values, including the corner
#x
x_min<-min(xn)
x_range<-max(xn)-x_min
xn_scaled<-(xn-x_min)/x_range
destination_x<-(point_x-x_min)/x_range #target point x coords, scaled
#y
y_min<-min(yn)
y_range<-max(yn)-y_min
yn_scaled<-(yn-y_min)/y_range
destination_y<-(point_y-y_min)/y_range #target point y coords, scaled
#calculate distances
d_x<-(xn_scaled-destination_x)**2
d_y<-(yn_scaled-destination_y)**2
d_vector<-sqrt(d_x+d_y)
return(d_vector)
}
#define corner of the triangle
corner_x<-PC_c[1]
corner_y<-c_var[length(c_var)]
distance_vector<-dVector_calculator(PC_c, c_var, corner_x, corner_y)
plot(distance_vector, xlab="Position", ylab="Distance", main="Distances to corner")
#Objective is closest point to corner (closest to y=0 in plot)
#So the objective is min distance
pc_cutoff<-which.min(distance_vector)
plot(pca_data$`Cumulative Proportion`, xlab="PC component number", ylab="Cumulative variance", main="Elbow plot for PC component cutoff", lwd=2)
abline(v=pc_cutoff, col="blue", lwd=2)
ctf_data<-as.data.frame(sc_pca$x[,1:pc_cutoff])
##aquests son valors transformats?? scikit =fit_transform es el mateix en prcomp q $x? o he d efer .predict?
set.seed(42)
shortened_pca<-prcomp(ctf_data)
shortened_umap<-umap(ctf_data, n_epochs=1500, min_dist=0.9, n_neighbors=35)
set.seed(42)
total_means<-c()
for (k in 1:20){
kmeans_res<-kmeans(ctf_data, k)
mean_res<-mean(kmeans_res$withinss)
total_means<-c(total_means, mean_res)
}
#png("../report/presentation/images/Elbow_kmeans2.png", width=1600, height=800)
plot(1:20, total_means, xlab="NÂº of clusters", ylab="Total means", main="Cluster elbow for Kmeans", type="b", lwd=2)
abline(v=1, col="red", lwd=2)
abline(h=total_means[length(total_means)], col="red", lwd=2)
#abline(v=km_num, col="blue", lwd=2)
#dev.off()
#define corner coordinates
corner_x<-1
corner_y<-total_means[length(total_means)]
#Get distance from each point to corner
distance_vector<-dVector_calculator(1:20, total_means, corner_x, corner_y)
plot(distance_vector, xlab="Position", ylab="Distance", main="Distances to corner", lwd=2)
#choose number of clusters
km_num<-which.min(distance_vector)
set.seed(42)
kres<-kmeans(ctf_data, km_num)
plot(shortened_umap$layout, col=kres$cluster, lwd=3)
setwd("..")
#png("../report/manuscript/images/Kmean_pcaColor.png", width=1600, height=800)
plot(shortened_pca$x, col=kres$cluster, lwd=3, main=paste0("PCA for ", ME, " module\nK-means centroids=", km_num))
#dev.off()
setwd("..") #set path to general annotation_code directory
write.table(geneCor, paste0("./correlation_tables/", ME, "_geneCorrelation.txt"), sep="\t")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, fig.width=16, fig.height=8)
knitr::opts_chunk$set(root.dir = "..") #does not work
knitr::opts_chunk$set
getwd()
library(WGCNA)
allowWGCNAThreads()
library(randomcoloR)
library(edgeR)
library(tidyverse)
library(dplyr)
library(grid)
library(gridExtra)
#devtools::install_github("kevinblighe/CorLevelPlot")
library(CorLevelPlot)
library(ggpubr)
library(plotly)
library(factoextra)
library(umap)
library(heatmaply)
library(dbscan)
library(reticulate)
reticulate::use_python("/usr/bin/python3", required=TRUE)
setwd("..") #set path to general annotation_code directory
dataPath<-paste0("../data/wlen/data_wlen.csv")
metadataPath<-paste0("../data/metadata.txt")
moduledata<-"../coexpression_code/geneModule.txt"
dataNL<-read.delim(dataPath, row.names=1, stringsAsFactors=TRUE)
metadata<-read.delim(metadataPath, header=T, row.names=1, stringsAsFactors=TRUE)
genemodule<-read.table(moduledata, stringsAsFactors=TRUE)
colnames(metadata)<-c("specie", "quality", "tissue_abv", "rep", "location")
moduleList<-levels(genemodule$modules)
table(genemodule$modules)
#Data selection
ME<-"blue" #green #lightcyan #turquoise
genemodule$genes<-rownames(genemodule)
MEgeneList<-rownames(genemodule[genemodule$modules==ME,])
dataNL<-dataNL[MEgeneList,]
if ("Length" %in% colnames(dataNL)){
length_vec<-dataNL$Length
}
dim(dataNL)
dim(metadata)
dataMatcher<-function(data, metadata){
options(warn=-1)
cat("Data begins with:" , dim(data))
cat("\nMetadata begins with:", dim(metadata))
#Match data to metadata
data <- data[, order(colnames(data))]
metadata <- metadata[order(rownames(metadata)), ]
cat("\nColumns data = Rows of metatdata?", all(rownames(metadata) == colnames(data)))
#If TRUE, columns of data and rows of metadata are matched
cat("\nRemove the excess from data")
data<-data[,colnames(data) %in% rownames(metadata)] #remove data not present in metadata
cat("\nData end with:" , dim(data))
cat("\nRemove the excess from metadata")
metadata<-metadata[rownames(metadata) %in% colnames(data),] #remove metadata not present in data
cat("\nMetadata end with:" , dim(metadata), "\n")
options(warn=0)
return(list(data, metadata))
}
jointData<-dataMatcher(dataNL, metadata)
dataNL<-jointData[[1]]
metadata<-jointData[[2]]
outDetect<-goodSamplesGenes(t(dataNL))
table(outDetect$goodGenes) #False genes are outliers
table(outDetect$goodSamples) #All samples are True = no outliers
dataNL<-dataNL[outDetect$goodGenes==TRUE,] #remove ouliers
if (exists("length_vec")){ #only if it exists
length_vec<-length_vec[outDetect$goodGenes==TRUE] #if length_vec exists remove outliers from there as well
}
#add the name of the species to the replicate, to be able to differentiate it
#save location
metadata$org_location<-as.factor(metadata$location)
#create specialized location
metadata$location<-paste(metadata$specie, metadata$location, sep="_")
metadata$location<-as.factor(metadata$location)
rsumer<-function(data, metadata, tissue_name){ #calculates the mean of all columns that belong to a location (ex: mean of all COB columns)
loc_mdata<-metadata[metadata$location == tissue_name, ] #filter metadata tissue (get metadata of location only)
data<-data[,colnames(data) %in% rownames(loc_mdata)] #get data of location only, based on metadata
if (1<ncol(data.frame(data))){ #If there's only 1 replicate, don't try to do the mean (it gives error)
data<-rowMeans(data) #calculate mean for each gene out of the locations(replicates)
}
return(as.data.frame(data))
}
tissue_data<-levels(metadata$location) #get list of tissue names
d_joint<-sapply(tissue_data, function(tissue_name) rsumer(dataNL, metadata, tissue_name)) #returns an array where each entry is a column with the mean data of the replicates (rows are genes)
repl_data<-as.data.frame(d_joint) #data joint by replicate
colnames(repl_data) = gsub(pattern = "*.data", replacement = "", x = tolower(colnames(repl_data))) #get column names to be only location
rownames(repl_data)<-rownames(dataNL) #rename rows to be genes again
#Create a column for the location+species
repl_meta<-as.data.frame(colnames(repl_data))
colnames(repl_meta)<-c("location")
#Split the created column and add 2 columns to repl_meta, one for the species and one for the tissue
temp_meta<-data.frame(t(data.frame(strsplit(as.character(repl_meta$location), "_"))))
repl_meta<-data.frame(repl_meta$location, temp_meta$X1, temp_meta$X2)
colnames(repl_meta)<-c("location", "species", "org_location")
keep<-colSums(repl_data)!=0
repl_data<-repl_data[,keep]
if (exists("length_vec")){ #if we have lengths
length_vec<-data.frame(Length=length_vec) #convert to dataframe
dge <- DGEList(repl_data, genes=length_vec) #use edgeR for normalization
dge <- calcNormFactors(dge)
Nrepl_data <- rpkm(dge, log=TRUE)
Nrepl_data<-as.data.frame(Nrepl_data)
NormType<-"RPKM"
}
#Filter low expression genes
keep<-apply(Nrepl_data, 1, max)>=0 #keep genes where the counts for at least one replicate are of at least 1 (0 because of log)
Nrepl_data<-Nrepl_data[keep,]
#Nrepl to data frame
Nrepl_data<-as.data.frame(Nrepl_data) #evetually transpose
#More genes kept after normalization and filtering than cpm
set.seed(42)
#Choose which genes to use
geneNumber<-round(nrow(Nrepl_data)/100 *10) #1% of genes
#get random genes
chosenGenes<-sample(rownames(Nrepl_data), geneNumber)
#obtain genes data
dataSection<-Nrepl_data[chosenGenes,]
#Save tissues
tissues<-colnames(dataSection)
#create genes column
dataSection$Gene<-rownames(dataSection)
#reshape data
long_data<-reshape(dataSection, direction="long",
v.names="Expression",
timevar="Tissue",
varying=tissues,
times=names(dataSection)[1:(ncol(dataSection)-1)]) #names(dataSection)[1:(ncol(dataSection)-1)]
ggplot(long_data, aes(x=Tissue, y=Expression, group=Gene)) +
geom_line(size=1, alpha=0.2) +
labs(x="Tissues", y="Expression", title=paste0("Module: ", ME, " at genes: ", geneNumber))+
theme_classic()+
theme(axis.text.x=element_text(angle=45, hjust=1, size=10),
axis.text.y=element_text(size=12),
legend.position="none",
axis.ticks=element_line(colour="black"),
axis.ticks.length=unit(8, "pt"),
panel.grid.major=element_line(color="red",
size=0.5))
ggplot(long_data, aes(x=Tissue, y=Expression, group=Gene)) +
geom_line(size=1, alpha=0.1) +
labs(x="Tissues", y="Expression", title=paste0("Module: ", ME, " at genes: ", geneNumber))+
theme_classic()+
theme(axis.text.x=element_text(angle=45, hjust=1, size=10),
axis.text.y=element_text(size=12),
legend.position="none",
axis.ticks=element_line(colour="black"),
axis.ticks.length=unit(8, "pt"))
Nrepl_dataT<-as.data.frame(t(Nrepl_data))
#correaltion table
geneCor<-cor(Nrepl_dataT, method="pearson")
geneList<-rownames(geneCor)
#Threshold choosing
ths<-seq(0,1, by=0.05)
ths_effect<- data.frame(ths, count=sapply(ths, function(t) sum(abs(geneCor)>t))) #count amount of correlations (all positive, as they all contribute)
ggplot(ths_effect, aes(x=ths, y=count))+
geom_line(color=ME, size=2)+
labs(x="Threshold", y="Correlaton count")+
geom_point(size=4)+
theme_bw()
#A good correlation threshold would be 0.7
#select above the diagonal
cor_vals<-geneCor[upper.tri(geneCor)]
#convert to data frame
cor_df<-data.frame(Correlation=cor_vals)
#PLot distribution
ggplot(cor_df, aes(x=Correlation))+
geom_histogram(binwidth=0.05, fill=ME, color="black")+
labs(title="Distribution of correlation values",
x="Correlation Coefficient",
y="Frequency")+
theme_minimal()
#Tends to appear bimodal
set.seed(42)
#Z-score scaling
sc_data<-scale(Nrepl_data)
#scaled pca
sc_pca<-prcomp(sc_data, scale=TRUE)
#pca plot
ggplot(sc_pca$x, aes(x=PC1, y=PC2))+
geom_point(size=3)+
theme_minimal()
#pca PC effect
pca_sum<-summary(sc_pca)
pca_data<-as.data.frame(t(pca_sum$importance))
c_var<-pca_data$`Cumulative Proportion`
PC_c<-1:length(c_var)
#search cutoff
plot(pca_data$`Cumulative Proportion`, xlab="PC component number", ylab="Cumulative variance", main="Elbow plot for PC component cutoff", lwd=2)
abline(v=PC_c[1], col="red", lwd=2)
abline(h=c_var[length(c_var)], col="red", lwd=2)
#function to calculate distance vector (distance to "triangle" corner)
dVector_calculator<-function(xn, yn, point_x, point_y){
#normalize values, including the corner
#x
x_min<-min(xn)
x_range<-max(xn)-x_min
xn_scaled<-(xn-x_min)/x_range
destination_x<-(point_x-x_min)/x_range #target point x coords, scaled
#y
y_min<-min(yn)
y_range<-max(yn)-y_min
yn_scaled<-(yn-y_min)/y_range
destination_y<-(point_y-y_min)/y_range #target point y coords, scaled
#calculate distances
d_x<-(xn_scaled-destination_x)**2
d_y<-(yn_scaled-destination_y)**2
d_vector<-sqrt(d_x+d_y)
return(d_vector)
}
#define corner of the triangle
corner_x<-PC_c[1]
corner_y<-c_var[length(c_var)]
distance_vector<-dVector_calculator(PC_c, c_var, corner_x, corner_y)
plot(distance_vector, xlab="Position", ylab="Distance", main="Distances to corner")
#Objective is closest point to corner (closest to y=0 in plot)
#So the objective is min distance
pc_cutoff<-which.min(distance_vector)
plot(pca_data$`Cumulative Proportion`, xlab="PC component number", ylab="Cumulative variance", main="Elbow plot for PC component cutoff", lwd=2)
abline(v=pc_cutoff, col="blue", lwd=2)
ctf_data<-as.data.frame(sc_pca$x[,1:pc_cutoff])
##aquests son valors transformats?? scikit =fit_transform es el mateix en prcomp q $x? o he d efer .predict?
set.seed(42)
shortened_pca<-prcomp(ctf_data)
shortened_umap<-umap(ctf_data, n_epochs=1500, min_dist=0.9, n_neighbors=35)
set.seed(42)
total_means<-c()
for (k in 1:20){
kmeans_res<-kmeans(ctf_data, k)
mean_res<-mean(kmeans_res$withinss)
total_means<-c(total_means, mean_res)
}
#png("../report/presentation/images/Elbow_kmeans2.png", width=1600, height=800)
plot(1:20, total_means, xlab="NÂº of clusters", ylab="Total means", main="Cluster elbow for Kmeans", type="b", lwd=2)
abline(v=1, col="red", lwd=2)
abline(h=total_means[length(total_means)], col="red", lwd=2)
#abline(v=km_num, col="blue", lwd=2)
#dev.off()
#define corner coordinates
corner_x<-1
corner_y<-total_means[length(total_means)]
#Get distance from each point to corner
distance_vector<-dVector_calculator(1:20, total_means, corner_x, corner_y)
plot(distance_vector, xlab="Position", ylab="Distance", main="Distances to corner", lwd=2)
#choose number of clusters
km_num<-which.min(distance_vector)
set.seed(42)
kres<-kmeans(ctf_data, km_num)
plot(shortened_umap$layout, col=kres$cluster, lwd=3)
setwd("..")
#png("../report/manuscript/images/Kmean_pcaColor.png", width=1600, height=800)
plot(shortened_pca$x, col=kres$cluster, lwd=3, main=paste0("PCA for ", ME, " module\nK-means centroids=", km_num))
#dev.off()
mp<-ncol(ctf_data)+1
#eps: elbow plot, choose shaprest point in bend
kNNdistplot(ctf_data, k=mp)
#3 is chosen, as the other inflection points produce no clusters
dbres<-dbscan(ctf_data, eps=3, minPts=mp)
plot(shortened_umap$layout, col=dbres$cluster+1, lwd=3)
setwd("..") #set path to general annotation_code directory
write.table(geneCor, paste0("./correlation_tables/", ME, "_geneCorrelation.txt"), sep="\t")
